{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de767f5a",
   "metadata": {},
   "source": [
    "# APF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c12626",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6878485d",
   "metadata": {},
   "source": [
    "## APF test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f363b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PARAMETERS ===\n",
    "NUM_AGENTS = 500\n",
    "GOAL_TOL = 0.001\n",
    "STEP_SIZE = 0.05\n",
    "K_ATTR = 1.0      # Attractive potential gain\n",
    "K_REP = 0.0002    # Repulsive potential gain\n",
    "REPULSION_RADIUS = 0.55\n",
    "MAX_REP_FORCE = 1.0\n",
    "MIN_DIST = 0.05   # Prevent division by very small values\n",
    "MAX_STEP = 0.07   # Clamp maximum step per agent\n",
    "DAMPING = 0.7     # Optional: smooth movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a287d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# === INITIAL CONDITIONS ===\n",
    "np.random.seed(0)\n",
    "positions = np.random.rand(NUM_AGENTS, 2) * np.array((-2, 1))\n",
    "\n",
    "# === RANDOM GAUSSIAN GOALS ===\n",
    "# goals = np.tile(np.array([1, 0]), (NUM_AGENTS, 1) )\n",
    "goal_mean = np.array([1.0, 1.0])\n",
    "goal_cov = np.array([[0.05, 0], [0, 1]])  # Small spread\n",
    "goals = np.random.multivariate_normal(mean=goal_mean, cov=goal_cov, size=NUM_AGENTS)\n",
    "\n",
    "# === APF PLANNING FUNCTION ===\n",
    "def compute_apf_forces(pos, goals):\n",
    "    forces = np.zeros_like(pos)\n",
    "    for i in range(len(pos)):\n",
    "        # Attractive force\n",
    "        diff = goals[i] - pos[i]\n",
    "        f_attr = K_ATTR * diff\n",
    "\n",
    "        # Repulsive force from other agents\n",
    "        f_rep = np.zeros(2)\n",
    "        \n",
    "        for j in range(len(pos)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            diff_ij = pos[i] - pos[j]\n",
    "            dist = np.linalg.norm(diff_ij)\n",
    "            if dist < REPULSION_RADIUS and dist > 1e-6:\n",
    "                # Clamp small distances to avoid singularity\n",
    "                dist_clamped = max(dist, MIN_DIST)\n",
    "                rep_mag = K_REP * (1.0 / dist_clamped - 1.0 / REPULSION_RADIUS) / (dist_clamped**2)\n",
    "                rep_mag = np.clip(rep_mag, 0, MAX_REP_FORCE)\n",
    "                f_rep += rep_mag * (diff_ij / dist_clamped)\n",
    "\n",
    "        forces[i] = f_attr + f_rep\n",
    "    return forces\n",
    "\n",
    "# === VISUALIZATION SETUP ===\n",
    "fig, ax = plt.subplots()\n",
    "scat = ax.scatter([], [], c='blue')\n",
    "goal_plot = ax.scatter(goals[:, 0], goals[:, 1], c='green', marker='x')\n",
    "ax.set_xlim(-1, 3)\n",
    "ax.set_ylim(-1, 3)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# === SIMULATION LOOP ===\n",
    "stopped = False\n",
    "\n",
    "def update(frame):\n",
    "    global positions, stopped\n",
    "\n",
    "    if not stopped:\n",
    "        dists_to_goals = np.linalg.norm(positions - goals, axis=1)\n",
    "        if np.any(dists_to_goals < GOAL_TOL):\n",
    "            stopped = True\n",
    "        else:\n",
    "            forces = compute_apf_forces(positions, goals)\n",
    "            for i in range(len(positions)):\n",
    "                step = STEP_SIZE * forces[i]\n",
    "                norm = np.linalg.norm(step)\n",
    "                if norm > MAX_STEP:\n",
    "                    step = MAX_STEP * step / norm\n",
    "                positions[i] += DAMPING * step  # Apply damping\n",
    "\n",
    "    scat.set_offsets(positions)\n",
    "    return scat,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=200, interval=100, blit=True)\n",
    "plt.title(\"Multi-Agent APF with Stability Control\")\n",
    "ani.save(\"solutions/apf_stability.mp4\", writer=\"ffmpeg\", fps=24)\n",
    "plt.close()\n",
    "\n",
    "from IPython.display import Video\n",
    "Video(filename=\"solutions/apf_stability.mp4\", embed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db0f683",
   "metadata": {},
   "source": [
    "## APF waypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43010ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from st_gaussian_prm.solvers.micro.apf import APF\n",
    "\n",
    "num_agents = 30\n",
    "\n",
    "# generate per agent trajectory\n",
    "\n",
    "means = np.array([(0., 0.), (5., 0.), (8, 1), (10, 5)])\n",
    "covs = np.array([[(1, 0), (0, 5)], [(3, 0), (0, 1)], [(1, 0), (0, 1)],[(1, 0), (0, 1)]])\n",
    "\n",
    "class GaussianNode:\n",
    "    def __init__ (self, mean, cov):\n",
    "        self.mean = mean\n",
    "        self.cov = cov\n",
    "    \n",
    "g_nodes = []\n",
    "\n",
    "for mean, cov in zip(means, covs):\n",
    "    g_nodes.append(GaussianNode(mean, cov))\n",
    "\n",
    "g_paths = np.tile(np.arange(4), [num_agents, 1])\n",
    "\n",
    "# means = np.array([(0., 0.), (5., 0.)])\n",
    "# covs = [np.eye(2) for _ in means]\n",
    "\n",
    "\n",
    "apf_config = {\n",
    "    \"k_attr\": 0.5,\n",
    "    \"k_rep\": 5.2,\n",
    "    \"step_size\": 0.05,\n",
    "    \"repulsion_radius\": 0.4,\n",
    "    \"goal_chisq_threshold\": 5.991, # 95% CI\n",
    "    \"max_rep_force\": 1.0,\n",
    "    \"min_dist\": 0.05,\n",
    "    \"max_step\": 0.07,\n",
    "    \"damping\": 0.7\n",
    "}\n",
    "\n",
    "trajectories =APF(g_paths, g_nodes, **apf_config).solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bbe772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "colors = plt.cm.jet(np.linspace(0, 1, num_agents))\n",
    "points = [ax.plot([], [], 'o', color=colors[i])[0] for i in range(num_agents)]\n",
    "\n",
    "ax.plot(trajectories[:, -1, 0], trajectories[:, -1, 1], 'x', color=\"green\") # plot goals\n",
    "ax.set_xlim(np.min(trajectories[:, :, 0]) - 1, np.max(trajectories[:, :, 0]) + 1)\n",
    "ax.set_ylim(np.min(trajectories[:, :, 1]) - 1, np.max(trajectories[:, :, 1]) + 1)\n",
    "ax.set_title(\"APF Trajectories\")\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "SKIP = 10\n",
    "def update(frame):\n",
    "    for i in range(num_agents):\n",
    "        x, y = trajectories[i, frame]\n",
    "        points[i].set_data([x], [y])\n",
    "    return points \n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=range(0, trajectories.shape[1], SKIP), interval=50, blit=True)\n",
    "\n",
    "ani.save(\"solutions/apf.mp4\", writer=\"ffmpeg\", fps=24)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "from IPython.display import Video\n",
    "Video(filename=\"solutions/apf.mp4\", embed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc1eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
